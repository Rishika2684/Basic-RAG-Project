{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORHheOdVJX5I",
        "outputId": "6536c24c-5f1a-44d5-c2cf-fadbd2af2b8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.12/dist-packages (0.3.30)\n",
            "Requirement already satisfied: langchainhub in /usr/local/lib/python3.12/dist-packages (0.1.21)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.12/dist-packages (1.1.0)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-0.3.8-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.3.77)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.43)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.10.1)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.28)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchainhub) (24.2)\n",
            "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in /usr/local/lib/python3.12/dist-packages (from langchainhub) (2.32.4.20250913)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.3.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.11.9)\n",
            "Requirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.4.2)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.35.0)\n",
            "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.15.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.75.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.0.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.17.4)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (34.1.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.2.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.3)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Collecting groq<1,>=0.30.0 (from langchain-groq)\n",
            "  Downloading groq-0.32.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.27.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: urllib3<2.4.0,>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain_community) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.25.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.58b0)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.4.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.2.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.13.2->chromadb) (0.35.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.1.10)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=0.3.75->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading langchain_groq-0.3.8-py3-none-any.whl (16 kB)\n",
            "Downloading groq-0.32.0-py3-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq, langchain-groq\n",
            "Successfully installed groq-0.32.0 langchain-groq-0.3.8\n"
          ]
        }
      ],
      "source": [
        "pip install langchain_community langchainhub chromadb langchain langchain-groq"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f7ae6b1"
      },
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ['GROQ_API_KEY'] = userdata.get('groqkey1')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8f63448",
        "outputId": "5af9e21f-44c3-4863-b3a7-25901ae301eb"
      },
      "source": [
        "pip install sentence-transformers"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.56.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.35.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.5)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.8.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "loader=WebBaseLoader(web_paths=['https://en.wikipedia.org/wiki/Retrieval-augmented_generation']) #put urls of your choice here\n",
        "docs=loader.load()\n",
        "print(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJpIP5_dL-iY",
        "outputId": "39eaa586-0b2c-4e75-cce6-edd41e4fc3de"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content='\\n\\n\\n\\nRetrieval-augmented generation - Wikipedia\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to content\\n\\n\\n\\n\\n\\n\\n\\nMain menu\\n\\n\\n\\n\\n\\nMain menu\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tNavigation\\n\\t\\n\\n\\nMain pageContentsCurrent eventsRandom articleAbout WikipediaContact us\\n\\n\\n\\n\\n\\n\\t\\tContribute\\n\\t\\n\\n\\nHelpLearn to editCommunity portalRecent changesUpload fileSpecial pages\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAppearance\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDonate\\n\\nCreate account\\n\\nLog in\\n\\n\\n\\n\\n\\n\\n\\n\\nPersonal tools\\n\\n\\n\\n\\n\\nDonate Create account Log in\\n\\n\\n\\n\\n\\n\\t\\tPages for logged out editors learn more\\n\\n\\n\\nContributionsTalk\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nContents\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n(Top)\\n\\n\\n\\n\\n\\n1\\nRAG and LLM Limitations\\n\\n\\n\\n\\n\\n\\n\\n\\n2\\nProcess\\n\\n\\n\\n\\nToggle Process subsection\\n\\n\\n\\n\\n\\n2.1\\nRAG key stages\\n\\n\\n\\n\\n\\n\\n2.1.1\\nIndexing\\n\\n\\n\\n\\n\\n\\n\\n\\n2.1.2\\nRetrieval\\n\\n\\n\\n\\n\\n\\n\\n\\n2.1.3\\nAugmentation\\n\\n\\n\\n\\n\\n\\n\\n\\n2.1.4\\nGeneration\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n3\\nImprovements\\n\\n\\n\\n\\nToggle Improvements subsection\\n\\n\\n\\n\\n\\n3.1\\nEncoder\\n\\n\\n\\n\\n\\n\\n\\n\\n3.2\\nRetriever-centric methods\\n\\n\\n\\n\\n\\n\\n\\n\\n3.3\\nLanguage model\\n\\n\\n\\n\\n\\n\\n\\n\\n3.4\\nChunking\\n\\n\\n\\n\\n\\n\\n\\n\\n3.5\\nKnowledge graphs\\n\\n\\n\\n\\n\\n\\n\\n\\n3.6\\nHybrid search\\n\\n\\n\\n\\n\\n\\n\\n\\n3.7\\nEvaluation and benchmarks\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n4\\nChallenges\\n\\n\\n\\n\\n\\n\\n\\n\\n5\\nReferences\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle the table of contents\\n\\n\\n\\n\\n\\n\\n\\nRetrieval-augmented generation\\n\\n\\n\\n15 languages\\n\\n\\n\\n\\nالعربيةCatalàČeštinaDeutschEspañolFrançais한국어ItalianoPolskiРусскийŚlůnskiTürkçeУкраїнськаTiếng Việt中文\\n\\nEdit links\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nArticleTalk\\n\\n\\n\\n\\n\\nEnglish\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nReadEditView history\\n\\n\\n\\n\\n\\n\\n\\nTools\\n\\n\\n\\n\\n\\nTools\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tActions\\n\\t\\n\\n\\nReadEditView history\\n\\n\\n\\n\\n\\n\\t\\tGeneral\\n\\t\\n\\n\\nWhat links hereRelated changesUpload filePermanent linkPage informationCite this pageGet shortened URLDownload QR code\\n\\n\\n\\n\\n\\n\\t\\tPrint/export\\n\\t\\n\\n\\nDownload as PDFPrintable version\\n\\n\\n\\n\\n\\n\\t\\tIn other projects\\n\\t\\n\\n\\nWikimedia CommonsWikidata item\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAppearance\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFrom Wikipedia, the free encyclopedia\\n\\n\\nType of information retrieval using LLMs\\nRetrieval-augmented generation (RAG) is a technique that enables large language models (LLMs) to retrieve and incorporate new information.[1] With RAG, LLMs do not respond to user queries until they refer to a specified set of documents. These documents supplement information from the LLM\\'s pre-existing training data.[2] This allows LLMs to use domain-specific and/or updated information that is not available in the training data.[2][3] For example, this helps LLM-based chatbots access internal company data or generate responses based on authoritative sources.\\nRAG improves large language models (LLMs) by incorporating information retrieval before generating responses.[4] Unlike traditional LLMs that rely on static training data, RAG pulls relevant text from databases, uploaded documents, or web sources.[1] According to Ars Technica, \"RAG is a way of improving LLM performance, in essence by blending the LLM process with a web search or other document look-up process to help LLMs stick to the facts.\" This method helps reduce AI hallucinations,[4][5] which have caused chatbots to describe policies that don\\'t exist, or recommend nonexistent legal cases to lawyers that are looking for citations to support their arguments.[6]\\nRAG also reduces the need to retrain LLMs with new data, saving on computational and financial costs.[1] Beyond efficiency gains, RAG also allows LLMs to include sources in their responses, so users can verify the cited sources. This provides greater transparency, as users can cross-check retrieved content to ensure accuracy and relevance.\\nThe term RAG was first introduced in a 2020 research paper[4] from Meta.[7][3]\\n\\n\\nRAG and LLM Limitations[edit]\\nLLMs can provide incorrect information. For example, when Google first demonstrated its LLM tool \"Google Bard\", the LLM provided incorrect information about the James Webb Space Telescope. This error contributed to a $100 billion decline in the company’s stock value.[6] RAG is used to prevent these errors, but it does not solve all the problems. For example, LLMs can generate misinformation even when pulling from factually correct sources if they misinterpret the context.[8] MIT Technology Review gives the example of an AI-generated response stating, \"The United States has had one Muslim president, Barack Hussein Obama.\" The model retrieved this from an academic book rhetorically titled Barack Hussein Obama: America’s First Muslim President? The LLM did not \"know\" or \"understand\" the context of the title, generating a false statement.[2]\\nLLMs with RAG are programmed to prioritize new information. This technique has been called \"prompt stuffing.\" Without prompt stuffing, the LLM\\'s input is generated by a user; with prompt stuffing, additional relevant context is added to this input to guide the model’s response. This approach provides the LLM with key information early in the prompt, encouraging it to prioritize the supplied data over pre-existing training knowledge.[9]\\n\\nProcess[edit]\\nRetrieval-augmented generation (RAG) enhances large language models (LLMs) by incorporating an information-retrieval mechanism that allows models to access and utilize additional data beyond their original training set. AWS states, \"RAG allows LLMs to retrieve relevant information from external data sources to generate more accurate and contextually relevant responses\" (\"indexing\").[10] This approach reduces reliance on static datasets, which can quickly become outdated. When a user submits a query, RAG uses a document retriever to search for relevant content from available sources before incorporating the retrieved information into the model\\'s response (\"retrieval\").[11] Ars Technica notes that \"when new information becomes available, rather than having to retrain the model, all that’s needed is to augment the model’s external knowledge base with the updated information\" (\"augmentation\").[6] By dynamically integrating relevant data, RAG enables LLMs to generate more informed and contextually grounded responses (\"generation\").[5] IBM states that \"in the generative phase, the LLM draws from the augmented prompt and its internal representation of its training data to synthesize an engaging answer tailored to the user in that instant\".[1]\\n\\nRAG key stages[edit]\\nIndexing[edit]\\nTypically, the data to be referenced is converted into LLM embeddings, numerical representations in the form of a large vector space.[8] RAG can be used on unstructured (usually text), semi-structured, or structured data (for example knowledge graphs).[12] These embeddings are then stored in a vector database to allow for document retrieval.[13]\\n\\nOverview of RAG process, combining external documents and user input into an LLM prompt to get tailored output\\nRetrieval[edit]\\nGiven a user query, a document retriever is first called to select the most relevant documents that will be used to augment the query.[2][4] This comparison can be done using a variety of methods, which depend in part on the type of indexing used.[1][12]\\n\\nAugmentation[edit]\\nThe model feeds this relevant retrieved information into the LLM via prompt engineering of the user\\'s original query.[10][14] Newer implementations (as of 2023[update]) can also incorporate specific augmentation modules with abilities such as expanding queries into multiple domains and using memory and self-improvement to learn from previous retrievals.[12]\\n\\nGeneration[edit]\\nFinally, the LLM can generate output based on both the query and the retrieved documents.[2][15] Some models incorporate extra steps to improve output, such as the re-ranking of retrieved information, context selection, and fine-tuning.[12]\\n\\nImprovements[edit]\\nImprovements to the basic process above can be applied at different stages in the RAG flow. \\n\\nEncoder[edit]\\nThese methods focus on the encoding of text as either dense or sparse vectors. Sparse vectors, which encode the identity of a word, are typically dictionary-length and contain mostly zeros. Dense vectors, which encode meaning, are more compact and contain fewer zeros. Various enhancements can improve the way similarities are calculated in the vector stores (databases).[16]\\n\\nPerformance improves by optimizing how vector similarities are calculated. Dot products enhance similarity scoring, while approximate nearest neighbor (ANN) searches improve retrieval efficiency over K-nearest neighbors (KNN) searches.[17]\\nAccuracy may be improved with Late Interactions, which allow the system to compare words more precisely after retrieval. This helps refine document ranking and improve search relevance.[18]\\nHybrid vector approaches may be used to combine dense vector representations with sparse one-hot vectors, taking advantage of the computational efficiency of sparse dot products over dense vector operations.[16]\\nOther retrieval techniques focus on improving accuracy by refining how documents are selected. Some retrieval methods combine sparse representations, such as SPLADE, with query expansion strategies to improve search accuracy and recall.[19]\\nRetriever-centric methods[edit]\\nThese methods aim to enhance the quality of document retrieval in vector databases:\\n\\nPre-training the retriever using the Inverse Cloze Task (ICT), a technique that helps the model learn retrieval patterns by predicting masked text within documents.[20]\\nProgressive data augmentation, as used in Diverse Augmentation for Generalizable Dense Retrieval (DRAGON), improves dense retrieval by sampling difficult negative examples during training.[21]\\nSupervised retriever optimization aligns retrieval probabilities with the generator model’s likelihood distribution. This involves retrieving the top-k vectors for a given prompt, scoring the generated response’s perplexity, and minimizing KL divergence between the retriever’s selections and the model’s likelihoods to refine retrieval.[22]\\nReranking techniques can refine retriever performance by prioritizing the most relevant retrieved documents during training.[23]\\n\\n\\nLanguage model[edit]\\n\\nRetro language model for RAG.  Each Retro block consists of Attention, Chunked Cross Attention, and Feed Forward layers.  Black-lettered boxes show data being changed, and blue lettering shows the algorithm performing the changes.\\nBy redesigning the language model with the retriever in mind, a 25-time smaller network can get comparable perplexity as its much larger counterparts.[24] Because it is trained from scratch, this method (Retro) incurs the high cost of training runs that the original RAG scheme avoided. The hypothesis is that by giving domain knowledge during training, Retro needs less focus on the domain and can devote its smaller weight resources only to language semantics. The redesigned language model is shown here.  \\nIt has been reported that Retro is not reproducible, so modifications were made to make it so.  The more reproducible version is called Retro++ and includes in-context RAG.[25]\\n\\nChunking[edit]\\nChunking involves various strategies for breaking up the data into vectors so the retriever can find details in it.[13]\\n\\n\\nDifferent data styles have patterns that correct chunking can take advantage of.\\nThree types of chunking strategies are:[citation needed]\\n\\nFixed length with overlap. This is fast and easy. Overlapping consecutive chunks helps to maintain semantic context across chunks.\\nSyntax-based chunks can break the document up into sentences. Libraries such as spaCy or NLTK can also help.\\nFile format-based chunking. Certain file types have natural chunks built in, and it\\'s best to respect them. For example, code files are best chunked and vectorized as whole functions or classes. HTML files should leave <table> or base64 encoded <img> elements intact. Similar considerations should be taken for pdf files. Libraries such as Unstructured or Langchain can assist with this method.\\nKnowledge graphs[edit]\\nRather than using documents as a source to vectorize and retrieve from, Knowledge Graphs can be used. One can start with a set of documents, books, or other bodies of text, and convert them to a knowledge graph using one of many methods, including language models. Once the knowledge graph is created, subgraphs can be vectorized, stored in a vector database, and used for retrieval as in plain RAG. The advantage here is that graphs has more recognizable structure than strings of text and this structure can help retrieve more relevant facts for generation. Sometimes this approach is called GraphRAG.[26]\\n\\nHybrid search[edit]\\nSometimes vector database searches can miss key facts needed to answer a user\\'s question. One way to mitigate this is to do a traditional text search, add those results to the text chunks linked to the retrieved vectors from the vector search, and feed the combined hybrid text into the language model for generation.[citation needed]\\n\\nEvaluation and benchmarks[edit]\\nRAG systems are commonly evaluated using benchmarks designed to test retrievability, retrieval accuracy and generative quality. Popular datasets include BEIR, a suite of information retrieval tasks across diverse domains, and Natural Questions or Google QA for open-domain QA.[citation needed]\\n\\nChallenges[edit]\\nRAG is not a complete solution to the problem of hallucinations in LLMs. According to Ars Technica, \"It is not a direct solution because the LLM can still hallucinate around the source material in its response.\"[6]\\nWhile RAG improves the accuracy of large language models (LLMs), it does not eliminate all challenges. One limitation is that while RAG reduces the need for frequent model retraining, it does not remove it entirely. Additionally, LLMs may struggle to recognize when they lack sufficient information to provide a reliable response. Without specific training, models may generate answers even when they should indicate uncertainty. According to IBM, this issue can arise when the model lacks the ability to assess its own knowledge limitations.[1]\\nRAG systems may retrieve factually correct but misleading sources, leading to errors in interpretation. In some cases, an LLM may extract statements from a source without considering its context, resulting in an incorrect conclusion.[11] Additionally, when faced with conflicting information RAG models may struggle to determine which source is accurate. The worst case outcome of this limitation is that the model may combine details from multiple sources producing responses that merge outdated and updated information in a misleading manner. According to the MIT Technology Review, these issues occur because RAG systems may misinterpret the data they retrieve.[2]\\n\\nReferences[edit]\\n\\n^ a b c d e f \"What is retrieval-augmented generation?\". IBM. 22 August 2023. Retrieved 7 March 2025.\\n\\n^ a b c d e f \"Why Google\\'s AI Overviews gets things wrong\". MIT Technology Review. 31 May 2024. Retrieved 7 March 2025.\\n\\n^ a b Singhal, Rahul (Nov 30, 2023). \"The Power Of RAG: How Retrieval-Augmented Generation Enhances Generative AI\". Forbes.\\n\\n^ a b c d Kiela Douwe, Lewis Patrick, Perez Ethan, Piktus Aleksandra, Petroni Fabio, Karpukhin Vladimir, Goyal Naman, Küttler Heinrich, Lewis Mike, Yih Wen-Tau, Rocktäschel Tim, Riedel Sebastian (2020). Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. pp.\\xa09459–9474. arXiv:2005.11401. ISBN\\xa0978-1-7138-2954-6.{{cite book}}:  CS1 maint: multiple names: authors list (link)\\n\\n^ a b Turow Jon, Kiela Douwe (March 26, 2025). \"RAG Inventor Talks Agents, Grounded AI, and Enterprise Impact\". Madrona.\\n\\n^ a b c d \"Can a technology called RAG keep AI models from making stuff up?\". Ars Technica. 6 June 2024. Retrieved 7 March 2025.\\n\\n^ \"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\". ai.meta.com. 2020.\\n\\n^ a b Xu, Sherlock (January 25, 2024). \"Understanding Retrieval-Augmented Generation: Part 1\". www.bentoml.com.\\n\\n^ \"Mitigating LLM hallucinations in text summarisation\". BBC. 20 June 2024. Retrieved 7 March 2025.\\n\\n^ a b \"What is RAG? - Retrieval-Augmented Generation AI Explained - AWS\". Amazon Web Services, Inc. Retrieved 16 July 2024.\\n\\n^ a b Kiela Douwe, Turck Matt (March 6, 2025). \"Top AI Researcher on GPT 4.5, DeepSeek and Agentic RAG | Douwe Kiela, CEO, Contextual AI\". YouTube.\\n\\n^ a b c d Gao, Yunfan; Xiong, Yun; Gao, Xinyu; Jia, Kangxiang; Pan, Jinliu; Bi, Yuxi; Dai, Yi; Sun, Jiawei; Wang, Meng; Wang, Haofen (2023). \"Retrieval-Augmented Generation for Large Language Models: A Survey\". arXiv:2312.10997 [cs.CL].\\n\\n^ a b Sankar, Shrinivasan (Feb 13, 2024). \"Retrieval Augmented Generation(RAG) — A quick and comprehensive introduction\". ai-bites.net.\\n\\n^ Kiela Douwe, Ho Alan (Oct 13, 2023). \"Where did Retrieval Augmented Generation come from, and where is it going?\". YouTube.\\n\\n^ Lewis, Patrick; Perez, Ethan; Piktus, Aleksandra; Petroni, Fabio; Karpukhin, Vladimir; Goyal, Naman; Küttler, Heinrich; Lewis, Mike; Yih, Wen-tau; Rocktäschel, Tim; Riedel, Sebastian; Kiela, Douwe (2020). \"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\". Advances in Neural Information Processing Systems. 33. Curran Associates, Inc.: 9459–9474. arXiv:2005.11401.\\n\\n^ a b Luan, Yi; Eisenstein, Jacob; Toutanova, Kristina; Collins, Michael (26 April 2021). \"Sparse, Dense, and Attentional Representations for Text Retrieval\". Transactions of the Association for Computational Linguistics. 9: 329–345. arXiv:2005.00181. doi:10.1162/tacl_a_00369. Retrieved 15 March 2025.\\n\\n^ \"Information retrieval\". Microsoft. 10 January 2025. Retrieved 15 March 2025.\\n\\n^ Khattab, Omar; Zaharia, Matei (2020). \"ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT\". Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. pp.\\xa039–48. doi:10.1145/3397271.3401075. ISBN\\xa0978-1-4503-8016-4.\\n\\n^ Wang, Yup; Conroy, John M.; Molino, Neil; Yang, Julia; Green, Mike (2024). \"Laboratory for Analytic Sciences in TREC 2024 Retrieval Augmented Generation Track\". NIST TREC 2024. Retrieved 15 March 2025.\\n\\n^ Lee, Kenton; Chang, Ming-Wei; Toutanova, Kristina (2019). \"\"Latent Retrieval for Weakly Supervised Open Domain Question Answering\"\" (PDF).\\n\\n^ Lin, Sheng-Chieh; Asai, Akari; Li, Minghan; Oguz, Barlas; Lin, Jimmy; Mehdad, Yashar; Yih, Wen-tau; Chen, Xilun (January 2023). \"How to Train Your Dragon: Diverse Augmentation Towards Generalizable Dense Retrieval\". EMNLP. arXiv:2302.07452.\\n\\n^ Shi, Weijia; Min, Sewon; Yasunaga, Michihiro; Seo, Minjoon; James, Rich; Lewis, Mike; Zettlemoyer, Luke; Yih, Wen-tau (June 2024). \"REPLUG: Retrieval-Augmented Black-Box Language Models\". Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers). pp.\\xa08371–8384. arXiv:2301.12652. doi:10.18653/v1/2024.naacl-long.463. Retrieved 16 March 2025.\\n\\n^ Ram, Ori; Levine, Yoav; Dalmedigos, Itay; Muhlgay, Dor; Shashua, Amnon; Leyton-Brown, Kevin; Shoham, Yoav (2023). \"In-Context Retrieval-Augmented Language Models\". Transactions of the Association for Computational Linguistics. 11: 1316–1331. arXiv:2302.00083. doi:10.1162/tacl_a_00605. Retrieved 16 March 2025.\\n\\n^ Borgeaud, Sebastian; Mensch, Arthur (2021). \"Improving language models by retrieving from trillions of tokens\" (PDF).\\n\\n^ Wang, Boxin; Ping, Wei; Xu, Peng; McAfee, Lawrence; Liu, Zihan; Shoeybi, Mohammad; Dong, Yi; Kuchaiev, Oleksii; Li, Bo; Xiao, Chaowei; Anandkumar, Anima; Catanzaro, Bryan (2023). \"Shall We Pretrain Autoregressive Language Models with Retrieval? A Comprehensive Study\". Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. pp.\\xa07763–7786. doi:10.18653/v1/2023.emnlp-main.482.\\n\\n^ Edge, Darren; Trinh, Ha; Cheng, Newman; Bradley, Joshua; Chao, Alex; Mody, Apurva; Truitt, Steven; Metropolitansky, Dasha; Ness, Robert Osazuwa (2024). \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\". arXiv:2404.16130 [cs.CL].\\n\\n\\nvteGenerative AIConcepts\\nAutoencoder\\nDeep learning\\nFine-tuning\\nFoundation model\\nGenerative adversarial network\\nGenerative pre-trained transformer\\nLarge language model\\nModel Context Protocol\\nNeural network\\nPrompt engineering\\nReinforcement learning from human feedback\\nRetrieval-augmented generation\\nSelf-supervised learning\\nStochastic parrot\\nSynthetic data\\nTop-p sampling\\nTransformer\\nVariational autoencoder\\nVibe coding\\nVision transformer\\nWaluigi effect\\nWord embedding\\nChatbots\\nCharacter.ai\\nChatGPT\\nDeepSeek\\nErnie\\nGemini\\nGrok\\nCopilot\\nModelsText\\nClaude\\nGemini\\nGemma\\nGPT\\n1\\n2\\n3\\nJ\\n4\\n4o\\n4.5\\n4.1\\nOSS\\n5\\nLlama\\no1\\no3\\no4-mini\\nQwen\\nCoding\\nBase44\\nClaude Code\\nCursor\\nDevstral\\nGitHub Copilot\\nKimi\\nQwen3-Coder\\nReplit\\nXcode\\nImage\\nAurora\\nFirefly\\nFlux\\nGPT Image 1\\nIdeogram\\nImagen\\nMidjourney\\nQwen-Image\\nRecraft\\nSeedream\\nStable Diffusion\\nVideo\\nDream Machine\\nHailuo AI\\nKling\\nMidjourney Video\\nRunway Gen\\nSeedance\\nSora\\nVeo\\nWan\\nSpeech\\n15.ai\\nEleven\\nMiniMax Speech 2.5\\nWaveNet\\nMusic\\nEleven Music\\nEndel\\nLyria\\nRiffusion\\nSuno AI\\nUdio\\nAgents\\nAgentforce\\nAutoGLM\\nAutoGPT\\nChatGPT Agent\\nDevin AI\\nManus\\nOpenAI Codex\\nOperator\\nReplit Agent\\nCompanies\\n01.AI\\nAleph Alpha\\nAnthropic\\nBaichuan\\nCanva\\nCognition AI\\nCohere\\nContextual AI\\nDeepSeek\\nElevenLabs\\nGoogle DeepMind\\nHeyGen\\nHugging Face\\nInflection AI\\nKrikey AI\\nKuaishou\\nLuma Labs\\nMeta AI\\nMiniMax\\nMistral AI\\nMoonshot AI\\nOpenAI\\nPerplexity AI\\nRunway\\nSafe Superintelligence\\nSalesforce\\nScale AI\\nSoundHound\\nStability AI\\nSynthesia\\nThinking Machines Lab\\nUpstage\\nxAI\\nZ.ai\\n\\n Category\\n\\nvteArtificial intelligence (AI)\\nHistory\\ntimeline\\nCompanies\\nProjects\\nConcepts\\nParameter\\nHyperparameter\\nLoss functions\\nRegression\\nBias–variance tradeoff\\nDouble descent\\nOverfitting\\nClustering\\nGradient descent\\nSGD\\nQuasi-Newton method\\nConjugate gradient method\\nBackpropagation\\nAttention\\nConvolution\\nNormalization\\nBatchnorm\\nActivation\\nSoftmax\\nSigmoid\\nRectifier\\nGating\\nWeight initialization\\nRegularization\\nDatasets\\nAugmentation\\nPrompt engineering\\nReinforcement learning\\nQ-learning\\nSARSA\\nImitation\\nPolicy gradient\\nDiffusion\\nLatent diffusion model\\nAutoregression\\nAdversary\\nRAG\\nUncanny valley\\nRLHF\\nSelf-supervised learning\\nReflection\\nRecursive self-improvement\\nHallucination\\nWord embedding\\nVibe coding\\nApplications\\nMachine learning\\nIn-context learning\\nArtificial neural network\\nDeep learning\\nLanguage model\\nLarge language model\\nNMT\\nReasoning language model\\nModel Context Protocol\\nIntelligent agent\\nArtificial human companion\\nHumanity\\'s Last Exam\\nArtificial general intelligence (AGI)\\nImplementationsAudio–visual\\nAlexNet\\nWaveNet\\nHuman image synthesis\\nHWR\\nOCR\\nComputer vision\\nSpeech synthesis\\n15.ai\\nElevenLabs\\nSpeech recognition\\nWhisper\\nFacial recognition\\nAlphaFold\\nText-to-image models\\nAurora\\nDALL-E\\nFirefly\\nFlux\\nIdeogram\\nImagen\\nMidjourney\\nRecraft\\nStable Diffusion\\nText-to-video models\\nDream Machine\\nRunway Gen\\nHailuo AI\\nKling\\nSora\\nVeo\\nMusic generation\\nRiffusion\\nSuno AI\\nUdio\\nText\\nWord2vec\\nSeq2seq\\nGloVe\\nBERT\\nT5\\nLlama\\nChinchilla AI\\nPaLM\\nGPT\\n1\\n2\\n3\\nJ\\nChatGPT\\n4\\n4o\\no1\\no3\\n4.5\\n4.1\\no4-mini\\n5\\nClaude\\nGemini\\nGemini (language model)\\nGemma\\nGrok\\nLaMDA\\nBLOOM\\nDBRX\\nProject Debater\\nIBM Watson\\nIBM Watsonx\\nGranite\\nPanGu-Σ\\nDeepSeek\\nQwen\\nDecisional\\nAlphaGo\\nAlphaZero\\nOpenAI Five\\nSelf-driving car\\nMuZero\\nAction selection\\nAutoGPT\\nRobot control\\nPeople\\nAlan Turing\\nWarren Sturgis McCulloch\\nWalter Pitts\\nJohn von Neumann\\nClaude Shannon\\nShun\\'ichi Amari\\nKunihiko Fukushima\\nTakeo Kanade\\nMarvin Minsky\\nJohn McCarthy\\nNathaniel Rochester\\nAllen Newell\\nCliff Shaw\\nHerbert A. Simon\\nOliver Selfridge\\nFrank Rosenblatt\\nBernard Widrow\\nJoseph Weizenbaum\\nSeymour Papert\\nSeppo Linnainmaa\\nPaul Werbos\\nGeoffrey Hinton\\nJohn Hopfield\\nJürgen Schmidhuber\\nYann LeCun\\nYoshua Bengio\\nLotfi A. Zadeh\\nStephen Grossberg\\nAlex Graves\\nJames Goodnight\\nAndrew Ng\\nFei-Fei Li\\nAlex Krizhevsky\\nIlya Sutskever\\nOriol Vinyals\\nQuoc V. Le\\nIan Goodfellow\\nDemis Hassabis\\nDavid Silver\\nAndrej Karpathy\\nAshish Vaswani\\nNoam Shazeer\\nAidan Gomez\\nJohn Schulman\\nMustafa Suleyman\\nJan Leike\\nDaniel Kokotajlo\\nFrançois Chollet\\nArchitectures\\nNeural Turing machine\\nDifferentiable neural computer\\nTransformer\\nVision transformer (ViT)\\nRecurrent neural network (RNN)\\nLong short-term memory (LSTM)\\nGated recurrent unit (GRU)\\nEcho state network\\nMultilayer perceptron (MLP)\\nConvolutional neural network (CNN)\\nResidual neural network (RNN)\\nHighway network\\nMamba\\nAutoencoder\\nVariational autoencoder (VAE)\\nGenerative adversarial network (GAN)\\nGraph neural network (GNN)\\n\\n Category\\n\\n\\n\\n\\n\\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Retrieval-augmented_generation&oldid=1314286272\"\\nCategories: Large language modelsNatural language processingInformation retrieval systemsGenerative artificial intelligenceHidden categories: CS1 maint: multiple names: authors listArticles with short descriptionShort description is different from WikidataArticles containing potentially dated statements from 2023All articles containing potentially dated statementsAll articles with unsourced statementsArticles with unsourced statements from August 2025Articles with unsourced statements from February 2025\\n\\n\\n\\n\\n\\n\\n This page was last edited on 30 September 2025, at 16:44\\xa0(UTC).\\nText is available under the Creative Commons Attribution-ShareAlike 4.0 License;\\nadditional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.\\n\\n\\nPrivacy policy\\nAbout Wikipedia\\nDisclaimers\\nContact Wikipedia\\nCode of Conduct\\nDevelopers\\nStatistics\\nCookie statement\\nMobile view\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle the table of contents\\n\\n\\n\\n\\n\\n\\n\\nRetrieval-augmented generation\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n15 languages\\n\\n\\nAdd topic\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
        "splits=text_splitter.split_documents(docs)\n",
        "print(splits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ti7LVxw-Nx4J",
        "outputId": "5a161d5a-30da-4a6c-8740-7b101e370279"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content='Retrieval-augmented generation - Wikipedia\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to content\\n\\n\\n\\n\\n\\n\\n\\nMain menu\\n\\n\\n\\n\\n\\nMain menu\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tNavigation\\n\\t\\n\\n\\nMain pageContentsCurrent eventsRandom articleAbout WikipediaContact us\\n\\n\\n\\n\\n\\n\\t\\tContribute\\n\\t\\n\\n\\nHelpLearn to editCommunity portalRecent changesUpload fileSpecial pages\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAppearance\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDonate\\n\\nCreate account\\n\\nLog in\\n\\n\\n\\n\\n\\n\\n\\n\\nPersonal tools\\n\\n\\n\\n\\n\\nDonate Create account Log in\\n\\n\\n\\n\\n\\n\\t\\tPages for logged out editors learn more\\n\\n\\n\\nContributionsTalk\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nContents\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n(Top)\\n\\n\\n\\n\\n\\n1\\nRAG and LLM Limitations\\n\\n\\n\\n\\n\\n\\n\\n\\n2\\nProcess\\n\\n\\n\\n\\nToggle Process subsection\\n\\n\\n\\n\\n\\n2.1\\nRAG key stages\\n\\n\\n\\n\\n\\n\\n2.1.1\\nIndexing\\n\\n\\n\\n\\n\\n\\n\\n\\n2.1.2\\nRetrieval\\n\\n\\n\\n\\n\\n\\n\\n\\n2.1.3\\nAugmentation\\n\\n\\n\\n\\n\\n\\n\\n\\n2.1.4\\nGeneration\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n3\\nImprovements\\n\\n\\n\\n\\nToggle Improvements subsection\\n\\n\\n\\n\\n\\n3.1\\nEncoder\\n\\n\\n\\n\\n\\n\\n\\n\\n3.2\\nRetriever-centric methods\\n\\n\\n\\n\\n\\n\\n\\n\\n3.3\\nLanguage model'), Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content='2.1.3\\nAugmentation\\n\\n\\n\\n\\n\\n\\n\\n\\n2.1.4\\nGeneration\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n3\\nImprovements\\n\\n\\n\\n\\nToggle Improvements subsection\\n\\n\\n\\n\\n\\n3.1\\nEncoder\\n\\n\\n\\n\\n\\n\\n\\n\\n3.2\\nRetriever-centric methods\\n\\n\\n\\n\\n\\n\\n\\n\\n3.3\\nLanguage model\\n\\n\\n\\n\\n\\n\\n\\n\\n3.4\\nChunking\\n\\n\\n\\n\\n\\n\\n\\n\\n3.5\\nKnowledge graphs\\n\\n\\n\\n\\n\\n\\n\\n\\n3.6\\nHybrid search\\n\\n\\n\\n\\n\\n\\n\\n\\n3.7\\nEvaluation and benchmarks\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n4\\nChallenges\\n\\n\\n\\n\\n\\n\\n\\n\\n5\\nReferences\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle the table of contents\\n\\n\\n\\n\\n\\n\\n\\nRetrieval-augmented generation\\n\\n\\n\\n15 languages\\n\\n\\n\\n\\nالعربيةCatalàČeštinaDeutschEspañolFrançais한국어ItalianoPolskiРусскийŚlůnskiTürkçeУкраїнськаTiếng Việt中文\\n\\nEdit links\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nArticleTalk\\n\\n\\n\\n\\n\\nEnglish\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nReadEditView history\\n\\n\\n\\n\\n\\n\\n\\nTools\\n\\n\\n\\n\\n\\nTools\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tActions\\n\\t\\n\\n\\nReadEditView history\\n\\n\\n\\n\\n\\n\\t\\tGeneral\\n\\t\\n\\n\\nWhat links hereRelated changesUpload filePermanent linkPage informationCite this pageGet shortened URLDownload QR code\\n\\n\\n\\n\\n\\n\\t\\tPrint/export\\n\\t\\n\\n\\nDownload as PDFPrintable version\\n\\n\\n\\n\\n\\n\\t\\tIn other projects\\n\\t\\n\\n\\nWikimedia CommonsWikidata item'), Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content='Print/export\\n\\t\\n\\n\\nDownload as PDFPrintable version\\n\\n\\n\\n\\n\\n\\t\\tIn other projects\\n\\t\\n\\n\\nWikimedia CommonsWikidata item\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAppearance\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFrom Wikipedia, the free encyclopedia'), Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content=\"Type of information retrieval using LLMs\\nRetrieval-augmented generation (RAG) is a technique that enables large language models (LLMs) to retrieve and incorporate new information.[1] With RAG, LLMs do not respond to user queries until they refer to a specified set of documents. These documents supplement information from the LLM's pre-existing training data.[2] This allows LLMs to use domain-specific and/or updated information that is not available in the training data.[2][3] For example, this helps LLM-based chatbots access internal company data or generate responses based on authoritative sources.\"), Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content='RAG improves large language models (LLMs) by incorporating information retrieval before generating responses.[4] Unlike traditional LLMs that rely on static training data, RAG pulls relevant text from databases, uploaded documents, or web sources.[1] According to Ars Technica, \"RAG is a way of improving LLM performance, in essence by blending the LLM process with a web search or other document look-up process to help LLMs stick to the facts.\" This method helps reduce AI hallucinations,[4][5] which have caused chatbots to describe policies that don\\'t exist, or recommend nonexistent legal cases to lawyers that are looking for citations to support their arguments.[6]'), Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content='RAG also reduces the need to retrain LLMs with new data, saving on computational and financial costs.[1] Beyond efficiency gains, RAG also allows LLMs to include sources in their responses, so users can verify the cited sources. This provides greater transparency, as users can cross-check retrieved content to ensure accuracy and relevance.\\nThe term RAG was first introduced in a 2020 research paper[4] from Meta.[7][3]'), Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content='RAG and LLM Limitations[edit]\\nLLMs can provide incorrect information. For example, when Google first demonstrated its LLM tool \"Google Bard\", the LLM provided incorrect information about the James Webb Space Telescope. This error contributed to a $100 billion decline in the company’s stock value.[6] RAG is used to prevent these errors, but it does not solve all the problems. For example, LLMs can generate misinformation even when pulling from factually correct sources if they misinterpret the context.[8] MIT Technology Review gives the example of an AI-generated response stating, \"The United States has had one Muslim president, Barack Hussein Obama.\" The model retrieved this from an academic book rhetorically titled Barack Hussein Obama: America’s First Muslim President? The LLM did not \"know\" or \"understand\" the context of the title, generating a false statement.[2]'), Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content='LLMs with RAG are programmed to prioritize new information. This technique has been called \"prompt stuffing.\" Without prompt stuffing, the LLM\\'s input is generated by a user; with prompt stuffing, additional relevant context is added to this input to guide the model’s response. This approach provides the LLM with key information early in the prompt, encouraging it to prioritize the supplied data over pre-existing training knowledge.[9]'), Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content='Process[edit]'), Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content='Retrieval-augmented generation (RAG) enhances large language models (LLMs) by incorporating an information-retrieval mechanism that allows models to access and utilize additional data beyond their original training set. AWS states, \"RAG allows LLMs to retrieve relevant information from external data sources to generate more accurate and contextually relevant responses\" (\"indexing\").[10] This approach reduces reliance on static datasets, which can quickly become outdated. When a user submits a query, RAG uses a document retriever to search for relevant content from available sources before incorporating the retrieved information into the model\\'s response (\"retrieval\").[11] Ars Technica notes that \"when new information becomes available, rather than having to retrain the model, all that’s needed is to augment the model’s external knowledge base with the updated information\" (\"augmentation\").[6] By dynamically integrating relevant data, RAG enables LLMs to generate more informed and'), Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content='needed is to augment the model’s external knowledge base with the updated information\" (\"augmentation\").[6] By dynamically integrating relevant data, RAG enables LLMs to generate more informed and contextually grounded responses (\"generation\").[5] IBM states that \"in the generative phase, the LLM draws from the augmented prompt and its internal representation of its training data to synthesize an engaging answer tailored to the user in that instant\".[1]'), Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content='RAG key stages[edit]\\nIndexing[edit]\\nTypically, the data to be referenced is converted into LLM embeddings, numerical representations in the form of a large vector space.[8] RAG can be used on unstructured (usually text), semi-structured, or structured data (for example knowledge graphs).[12] These embeddings are then stored in a vector database to allow for document retrieval.[13]\\n\\nOverview of RAG process, combining external documents and user input into an LLM prompt to get tailored output\\nRetrieval[edit]\\nGiven a user query, a document retriever is first called to select the most relevant documents that will be used to augment the query.[2][4] This comparison can be done using a variety of methods, which depend in part on the type of indexing used.[1][12]'), Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content=\"Augmentation[edit]\\nThe model feeds this relevant retrieved information into the LLM via prompt engineering of the user's original query.[10][14] Newer implementations (as of 2023[update]) can also incorporate specific augmentation modules with abilities such as expanding queries into multiple domains and using memory and self-improvement to learn from previous retrievals.[12]\\n\\nGeneration[edit]\\nFinally, the LLM can generate output based on both the query and the retrieved documents.[2][15] Some models incorporate extra steps to improve output, such as the re-ranking of retrieved information, context selection, and fine-tuning.[12]\\n\\nImprovements[edit]\\nImprovements to the basic process above can be applied at different stages in the RAG flow.\"), Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content='Improvements[edit]\\nImprovements to the basic process above can be applied at different stages in the RAG flow. \\n\\nEncoder[edit]\\nThese methods focus on the encoding of text as either dense or sparse vectors. Sparse vectors, which encode the identity of a word, are typically dictionary-length and contain mostly zeros. Dense vectors, which encode meaning, are more compact and contain fewer zeros. Various enhancements can improve the way similarities are calculated in the vector stores (databases).[16]'), Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content='Performance improves by optimizing how vector similarities are calculated. Dot products enhance similarity scoring, while approximate nearest neighbor (ANN) searches improve retrieval efficiency over K-nearest neighbors (KNN) searches.[17]\\nAccuracy may be improved with Late Interactions, which allow the system to compare words more precisely after retrieval. This helps refine document ranking and improve search relevance.[18]\\nHybrid vector approaches may be used to combine dense vector representations with sparse one-hot vectors, taking advantage of the computational efficiency of sparse dot products over dense vector operations.[16]\\nOther retrieval techniques focus on improving accuracy by refining how documents are selected. Some retrieval methods combine sparse representations, such as SPLADE, with query expansion strategies to improve search accuracy and recall.[19]\\nRetriever-centric methods[edit]\\nThese methods aim to enhance the quality of document retrieval in vector databases:'), Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content='Pre-training the retriever using the Inverse Cloze Task (ICT), a technique that helps the model learn retrieval patterns by predicting masked text within documents.[20]\\nProgressive data augmentation, as used in Diverse Augmentation for Generalizable Dense Retrieval (DRAGON), improves dense retrieval by sampling difficult negative examples during training.[21]\\nSupervised retriever optimization aligns retrieval probabilities with the generator model’s likelihood distribution. This involves retrieving the top-k vectors for a given prompt, scoring the generated response’s perplexity, and minimizing KL divergence between the retriever’s selections and the model’s likelihoods to refine retrieval.[22]\\nReranking techniques can refine retriever performance by prioritizing the most relevant retrieved documents during training.[23]\\n\\n\\nLanguage model[edit]'), Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content='Language model[edit]\\n\\nRetro language model for RAG.  Each Retro block consists of Attention, Chunked Cross Attention, and Feed Forward layers.  Black-lettered boxes show data being changed, and blue lettering shows the algorithm performing the changes.\\nBy redesigning the language model with the retriever in mind, a 25-time smaller network can get comparable perplexity as its much larger counterparts.[24] Because it is trained from scratch, this method (Retro) incurs the high cost of training runs that the original RAG scheme avoided. The hypothesis is that by giving domain knowledge during training, Retro needs less focus on the domain and can devote its smaller weight resources only to language semantics. The redesigned language model is shown here.  \\nIt has been reported that Retro is not reproducible, so modifications were made to make it so.  The more reproducible version is called Retro++ and includes in-context RAG.[25]'), Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content='Chunking[edit]\\nChunking involves various strategies for breaking up the data into vectors so the retriever can find details in it.[13]\\n\\n\\nDifferent data styles have patterns that correct chunking can take advantage of.\\nThree types of chunking strategies are:[citation needed]'), Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content=\"Fixed length with overlap. This is fast and easy. Overlapping consecutive chunks helps to maintain semantic context across chunks.\\nSyntax-based chunks can break the document up into sentences. Libraries such as spaCy or NLTK can also help.\\nFile format-based chunking. Certain file types have natural chunks built in, and it's best to respect them. For example, code files are best chunked and vectorized as whole functions or classes. HTML files should leave <table> or base64 encoded <img> elements intact. Similar considerations should be taken for pdf files. Libraries such as Unstructured or Langchain can assist with this method.\\nKnowledge graphs[edit]\"), Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content='Knowledge graphs[edit]\\nRather than using documents as a source to vectorize and retrieve from, Knowledge Graphs can be used. One can start with a set of documents, books, or other bodies of text, and convert them to a knowledge graph using one of many methods, including language models. Once the knowledge graph is created, subgraphs can be vectorized, stored in a vector database, and used for retrieval as in plain RAG. The advantage here is that graphs has more recognizable structure than strings of text and this structure can help retrieve more relevant facts for generation. Sometimes this approach is called GraphRAG.[26]'), Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content=\"Hybrid search[edit]\\nSometimes vector database searches can miss key facts needed to answer a user's question. One way to mitigate this is to do a traditional text search, add those results to the text chunks linked to the retrieved vectors from the vector search, and feed the combined hybrid text into the language model for generation.[citation needed]\\n\\nEvaluation and benchmarks[edit]\\nRAG systems are commonly evaluated using benchmarks designed to test retrievability, retrieval accuracy and generative quality. Popular datasets include BEIR, a suite of information retrieval tasks across diverse domains, and Natural Questions or Google QA for open-domain QA.[citation needed]\"), Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content='Challenges[edit]\\nRAG is not a complete solution to the problem of hallucinations in LLMs. According to Ars Technica, \"It is not a direct solution because the LLM can still hallucinate around the source material in its response.\"[6]\\nWhile RAG improves the accuracy of large language models (LLMs), it does not eliminate all challenges. One limitation is that while RAG reduces the need for frequent model retraining, it does not remove it entirely. Additionally, LLMs may struggle to recognize when they lack sufficient information to provide a reliable response. Without specific training, models may generate answers even when they should indicate uncertainty. According to IBM, this issue can arise when the model lacks the ability to assess its own knowledge limitations.[1]'), Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content='RAG systems may retrieve factually correct but misleading sources, leading to errors in interpretation. In some cases, an LLM may extract statements from a source without considering its context, resulting in an incorrect conclusion.[11] Additionally, when faced with conflicting information RAG models may struggle to determine which source is accurate. The worst case outcome of this limitation is that the model may combine details from multiple sources producing responses that merge outdated and updated information in a misleading manner. According to the MIT Technology Review, these issues occur because RAG systems may misinterpret the data they retrieve.[2]'), Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content='References[edit]\\n\\n^ a b c d e f \"What is retrieval-augmented generation?\". IBM. 22 August 2023. Retrieved 7 March 2025.\\n\\n^ a b c d e f \"Why Google\\'s AI Overviews gets things wrong\". MIT Technology Review. 31 May 2024. Retrieved 7 March 2025.\\n\\n^ a b Singhal, Rahul (Nov 30, 2023). \"The Power Of RAG: How Retrieval-Augmented Generation Enhances Generative AI\". Forbes.\\n\\n^ a b c d Kiela Douwe, Lewis Patrick, Perez Ethan, Piktus Aleksandra, Petroni Fabio, Karpukhin Vladimir, Goyal Naman, Küttler Heinrich, Lewis Mike, Yih Wen-Tau, Rocktäschel Tim, Riedel Sebastian (2020). Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. pp.\\xa09459–9474. arXiv:2005.11401. ISBN\\xa0978-1-7138-2954-6.{{cite book}}:  CS1 maint: multiple names: authors list (link)\\n\\n^ a b Turow Jon, Kiela Douwe (March 26, 2025). \"RAG Inventor Talks Agents, Grounded AI, and Enterprise Impact\". Madrona.'), Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content='^ a b Turow Jon, Kiela Douwe (March 26, 2025). \"RAG Inventor Talks Agents, Grounded AI, and Enterprise Impact\". Madrona.\\n\\n^ a b c d \"Can a technology called RAG keep AI models from making stuff up?\". Ars Technica. 6 June 2024. Retrieved 7 March 2025.\\n\\n^ \"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\". ai.meta.com. 2020.\\n\\n^ a b Xu, Sherlock (January 25, 2024). \"Understanding Retrieval-Augmented Generation: Part 1\". www.bentoml.com.\\n\\n^ \"Mitigating LLM hallucinations in text summarisation\". BBC. 20 June 2024. Retrieved 7 March 2025.\\n\\n^ a b \"What is RAG? - Retrieval-Augmented Generation AI Explained - AWS\". Amazon Web Services, Inc. Retrieved 16 July 2024.\\n\\n^ a b Kiela Douwe, Turck Matt (March 6, 2025). \"Top AI Researcher on GPT 4.5, DeepSeek and Agentic RAG | Douwe Kiela, CEO, Contextual AI\". YouTube.'), Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content='^ a b Kiela Douwe, Turck Matt (March 6, 2025). \"Top AI Researcher on GPT 4.5, DeepSeek and Agentic RAG | Douwe Kiela, CEO, Contextual AI\". YouTube.\\n\\n^ a b c d Gao, Yunfan; Xiong, Yun; Gao, Xinyu; Jia, Kangxiang; Pan, Jinliu; Bi, Yuxi; Dai, Yi; Sun, Jiawei; Wang, Meng; Wang, Haofen (2023). \"Retrieval-Augmented Generation for Large Language Models: A Survey\". arXiv:2312.10997 [cs.CL].\\n\\n^ a b Sankar, Shrinivasan (Feb 13, 2024). \"Retrieval Augmented Generation(RAG) — A quick and comprehensive introduction\". ai-bites.net.\\n\\n^ Kiela Douwe, Ho Alan (Oct 13, 2023). \"Where did Retrieval Augmented Generation come from, and where is it going?\". YouTube.'), Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content='^ Kiela Douwe, Ho Alan (Oct 13, 2023). \"Where did Retrieval Augmented Generation come from, and where is it going?\". YouTube.\\n\\n^ Lewis, Patrick; Perez, Ethan; Piktus, Aleksandra; Petroni, Fabio; Karpukhin, Vladimir; Goyal, Naman; Küttler, Heinrich; Lewis, Mike; Yih, Wen-tau; Rocktäschel, Tim; Riedel, Sebastian; Kiela, Douwe (2020). \"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\". Advances in Neural Information Processing Systems. 33. Curran Associates, Inc.: 9459–9474. arXiv:2005.11401.\\n\\n^ a b Luan, Yi; Eisenstein, Jacob; Toutanova, Kristina; Collins, Michael (26 April 2021). \"Sparse, Dense, and Attentional Representations for Text Retrieval\". Transactions of the Association for Computational Linguistics. 9: 329–345. arXiv:2005.00181. doi:10.1162/tacl_a_00369. Retrieved 15 March 2025.\\n\\n^ \"Information retrieval\". Microsoft. 10 January 2025. Retrieved 15 March 2025.'), Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content='^ \"Information retrieval\". Microsoft. 10 January 2025. Retrieved 15 March 2025.\\n\\n^ Khattab, Omar; Zaharia, Matei (2020). \"ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT\". Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. pp.\\xa039–48. doi:10.1145/3397271.3401075. ISBN\\xa0978-1-4503-8016-4.\\n\\n^ Wang, Yup; Conroy, John M.; Molino, Neil; Yang, Julia; Green, Mike (2024). \"Laboratory for Analytic Sciences in TREC 2024 Retrieval Augmented Generation Track\". NIST TREC 2024. Retrieved 15 March 2025.\\n\\n^ Lee, Kenton; Chang, Ming-Wei; Toutanova, Kristina (2019). \"\"Latent Retrieval for Weakly Supervised Open Domain Question Answering\"\" (PDF).\\n\\n^ Lin, Sheng-Chieh; Asai, Akari; Li, Minghan; Oguz, Barlas; Lin, Jimmy; Mehdad, Yashar; Yih, Wen-tau; Chen, Xilun (January 2023). \"How to Train Your Dragon: Diverse Augmentation Towards Generalizable Dense Retrieval\". EMNLP. arXiv:2302.07452.'), Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content='^ Shi, Weijia; Min, Sewon; Yasunaga, Michihiro; Seo, Minjoon; James, Rich; Lewis, Mike; Zettlemoyer, Luke; Yih, Wen-tau (June 2024). \"REPLUG: Retrieval-Augmented Black-Box Language Models\". Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers). pp.\\xa08371–8384. arXiv:2301.12652. doi:10.18653/v1/2024.naacl-long.463. Retrieved 16 March 2025.\\n\\n^ Ram, Ori; Levine, Yoav; Dalmedigos, Itay; Muhlgay, Dor; Shashua, Amnon; Leyton-Brown, Kevin; Shoham, Yoav (2023). \"In-Context Retrieval-Augmented Language Models\". Transactions of the Association for Computational Linguistics. 11: 1316–1331. arXiv:2302.00083. doi:10.1162/tacl_a_00605. Retrieved 16 March 2025.\\n\\n^ Borgeaud, Sebastian; Mensch, Arthur (2021). \"Improving language models by retrieving from trillions of tokens\" (PDF).'), Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content='^ Borgeaud, Sebastian; Mensch, Arthur (2021). \"Improving language models by retrieving from trillions of tokens\" (PDF).\\n\\n^ Wang, Boxin; Ping, Wei; Xu, Peng; McAfee, Lawrence; Liu, Zihan; Shoeybi, Mohammad; Dong, Yi; Kuchaiev, Oleksii; Li, Bo; Xiao, Chaowei; Anandkumar, Anima; Catanzaro, Bryan (2023). \"Shall We Pretrain Autoregressive Language Models with Retrieval? A Comprehensive Study\". Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. pp.\\xa07763–7786. doi:10.18653/v1/2023.emnlp-main.482.\\n\\n^ Edge, Darren; Trinh, Ha; Cheng, Newman; Bradley, Joshua; Chao, Alex; Mody, Apurva; Truitt, Steven; Metropolitansky, Dasha; Ness, Robert Osazuwa (2024). \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\". arXiv:2404.16130 [cs.CL].'), Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content='vteGenerative AIConcepts\\nAutoencoder\\nDeep learning\\nFine-tuning\\nFoundation model\\nGenerative adversarial network\\nGenerative pre-trained transformer\\nLarge language model\\nModel Context Protocol\\nNeural network\\nPrompt engineering\\nReinforcement learning from human feedback\\nRetrieval-augmented generation\\nSelf-supervised learning\\nStochastic parrot\\nSynthetic data\\nTop-p sampling\\nTransformer\\nVariational autoencoder\\nVibe coding\\nVision transformer\\nWaluigi effect\\nWord embedding\\nChatbots\\nCharacter.ai\\nChatGPT\\nDeepSeek\\nErnie\\nGemini\\nGrok\\nCopilot\\nModelsText\\nClaude\\nGemini\\nGemma\\nGPT\\n1\\n2\\n3\\nJ\\n4\\n4o\\n4.5\\n4.1\\nOSS\\n5\\nLlama\\no1\\no3\\no4-mini\\nQwen\\nCoding\\nBase44\\nClaude Code\\nCursor\\nDevstral\\nGitHub Copilot\\nKimi\\nQwen3-Coder\\nReplit\\nXcode\\nImage\\nAurora\\nFirefly\\nFlux\\nGPT Image 1\\nIdeogram\\nImagen\\nMidjourney\\nQwen-Image\\nRecraft\\nSeedream\\nStable Diffusion\\nVideo\\nDream Machine\\nHailuo AI\\nKling\\nMidjourney Video\\nRunway Gen\\nSeedance\\nSora\\nVeo\\nWan\\nSpeech\\n15.ai\\nEleven\\nMiniMax Speech 2.5\\nWaveNet\\nMusic\\nEleven Music\\nEndel\\nLyria\\nRiffusion'), Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content='Seedream\\nStable Diffusion\\nVideo\\nDream Machine\\nHailuo AI\\nKling\\nMidjourney Video\\nRunway Gen\\nSeedance\\nSora\\nVeo\\nWan\\nSpeech\\n15.ai\\nEleven\\nMiniMax Speech 2.5\\nWaveNet\\nMusic\\nEleven Music\\nEndel\\nLyria\\nRiffusion\\nSuno AI\\nUdio\\nAgents\\nAgentforce\\nAutoGLM\\nAutoGPT\\nChatGPT Agent\\nDevin AI\\nManus\\nOpenAI Codex\\nOperator\\nReplit Agent\\nCompanies\\n01.AI\\nAleph Alpha\\nAnthropic\\nBaichuan\\nCanva\\nCognition AI\\nCohere\\nContextual AI\\nDeepSeek\\nElevenLabs\\nGoogle DeepMind\\nHeyGen\\nHugging Face\\nInflection AI\\nKrikey AI\\nKuaishou\\nLuma Labs\\nMeta AI\\nMiniMax\\nMistral AI\\nMoonshot AI\\nOpenAI\\nPerplexity AI\\nRunway\\nSafe Superintelligence\\nSalesforce\\nScale AI\\nSoundHound\\nStability AI\\nSynthesia\\nThinking Machines Lab\\nUpstage\\nxAI\\nZ.ai'), Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content='Category'), Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content=\"vteArtificial intelligence (AI)\\nHistory\\ntimeline\\nCompanies\\nProjects\\nConcepts\\nParameter\\nHyperparameter\\nLoss functions\\nRegression\\nBias–variance tradeoff\\nDouble descent\\nOverfitting\\nClustering\\nGradient descent\\nSGD\\nQuasi-Newton method\\nConjugate gradient method\\nBackpropagation\\nAttention\\nConvolution\\nNormalization\\nBatchnorm\\nActivation\\nSoftmax\\nSigmoid\\nRectifier\\nGating\\nWeight initialization\\nRegularization\\nDatasets\\nAugmentation\\nPrompt engineering\\nReinforcement learning\\nQ-learning\\nSARSA\\nImitation\\nPolicy gradient\\nDiffusion\\nLatent diffusion model\\nAutoregression\\nAdversary\\nRAG\\nUncanny valley\\nRLHF\\nSelf-supervised learning\\nReflection\\nRecursive self-improvement\\nHallucination\\nWord embedding\\nVibe coding\\nApplications\\nMachine learning\\nIn-context learning\\nArtificial neural network\\nDeep learning\\nLanguage model\\nLarge language model\\nNMT\\nReasoning language model\\nModel Context Protocol\\nIntelligent agent\\nArtificial human companion\\nHumanity's Last Exam\\nArtificial general intelligence (AGI)\"), Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content=\"Language model\\nLarge language model\\nNMT\\nReasoning language model\\nModel Context Protocol\\nIntelligent agent\\nArtificial human companion\\nHumanity's Last Exam\\nArtificial general intelligence (AGI)\\nImplementationsAudio–visual\\nAlexNet\\nWaveNet\\nHuman image synthesis\\nHWR\\nOCR\\nComputer vision\\nSpeech synthesis\\n15.ai\\nElevenLabs\\nSpeech recognition\\nWhisper\\nFacial recognition\\nAlphaFold\\nText-to-image models\\nAurora\\nDALL-E\\nFirefly\\nFlux\\nIdeogram\\nImagen\\nMidjourney\\nRecraft\\nStable Diffusion\\nText-to-video models\\nDream Machine\\nRunway Gen\\nHailuo AI\\nKling\\nSora\\nVeo\\nMusic generation\\nRiffusion\\nSuno AI\\nUdio\\nText\\nWord2vec\\nSeq2seq\\nGloVe\\nBERT\\nT5\\nLlama\\nChinchilla AI\\nPaLM\\nGPT\\n1\\n2\\n3\\nJ\\nChatGPT\\n4\\n4o\\no1\\no3\\n4.5\\n4.1\\no4-mini\\n5\\nClaude\\nGemini\\nGemini (language model)\\nGemma\\nGrok\\nLaMDA\\nBLOOM\\nDBRX\\nProject Debater\\nIBM Watson\\nIBM Watsonx\\nGranite\\nPanGu-Σ\\nDeepSeek\\nQwen\\nDecisional\\nAlphaGo\\nAlphaZero\\nOpenAI Five\\nSelf-driving car\\nMuZero\\nAction selection\\nAutoGPT\\nRobot control\\nPeople\\nAlan Turing\\nWarren Sturgis McCulloch\\nWalter Pitts\"), Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content=\"Granite\\nPanGu-Σ\\nDeepSeek\\nQwen\\nDecisional\\nAlphaGo\\nAlphaZero\\nOpenAI Five\\nSelf-driving car\\nMuZero\\nAction selection\\nAutoGPT\\nRobot control\\nPeople\\nAlan Turing\\nWarren Sturgis McCulloch\\nWalter Pitts\\nJohn von Neumann\\nClaude Shannon\\nShun'ichi Amari\\nKunihiko Fukushima\\nTakeo Kanade\\nMarvin Minsky\\nJohn McCarthy\\nNathaniel Rochester\\nAllen Newell\\nCliff Shaw\\nHerbert A. Simon\\nOliver Selfridge\\nFrank Rosenblatt\\nBernard Widrow\\nJoseph Weizenbaum\\nSeymour Papert\\nSeppo Linnainmaa\\nPaul Werbos\\nGeoffrey Hinton\\nJohn Hopfield\\nJürgen Schmidhuber\\nYann LeCun\\nYoshua Bengio\\nLotfi A. Zadeh\\nStephen Grossberg\\nAlex Graves\\nJames Goodnight\\nAndrew Ng\\nFei-Fei Li\\nAlex Krizhevsky\\nIlya Sutskever\\nOriol Vinyals\\nQuoc V. Le\\nIan Goodfellow\\nDemis Hassabis\\nDavid Silver\\nAndrej Karpathy\\nAshish Vaswani\\nNoam Shazeer\\nAidan Gomez\\nJohn Schulman\\nMustafa Suleyman\\nJan Leike\\nDaniel Kokotajlo\\nFrançois Chollet\\nArchitectures\\nNeural Turing machine\\nDifferentiable neural computer\\nTransformer\\nVision transformer (ViT)\\nRecurrent neural network (RNN)\"), Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content='Mustafa Suleyman\\nJan Leike\\nDaniel Kokotajlo\\nFrançois Chollet\\nArchitectures\\nNeural Turing machine\\nDifferentiable neural computer\\nTransformer\\nVision transformer (ViT)\\nRecurrent neural network (RNN)\\nLong short-term memory (LSTM)\\nGated recurrent unit (GRU)\\nEcho state network\\nMultilayer perceptron (MLP)\\nConvolutional neural network (CNN)\\nResidual neural network (RNN)\\nHighway network\\nMamba\\nAutoencoder\\nVariational autoencoder (VAE)\\nGenerative adversarial network (GAN)\\nGraph neural network (GNN)'), Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content='Category\\n\\n\\n\\n\\n\\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Retrieval-augmented_generation&oldid=1314286272\"\\nCategories: Large language modelsNatural language processingInformation retrieval systemsGenerative artificial intelligenceHidden categories: CS1 maint: multiple names: authors listArticles with short descriptionShort description is different from WikidataArticles containing potentially dated statements from 2023All articles containing potentially dated statementsAll articles with unsourced statementsArticles with unsourced statements from August 2025Articles with unsourced statements from February 2025\\n\\n\\n\\n\\n\\n\\n This page was last edited on 30 September 2025, at 16:44\\xa0(UTC).\\nText is available under the Creative Commons Attribution-ShareAlike 4.0 License;\\nadditional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.'), Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content='Privacy policy\\nAbout Wikipedia\\nDisclaimers\\nContact Wikipedia\\nCode of Conduct\\nDevelopers\\nStatistics\\nCookie statement\\nMobile view\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle the table of contents\\n\\n\\n\\n\\n\\n\\n\\nRetrieval-augmented generation\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n15 languages\\n\\n\\nAdd topic')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(splits))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHNzRl4aPj5w",
        "outputId": "b658a820-06ac-4290-fde3-1f5c142eac9c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "embeddings = HuggingFaceEmbeddings()\n",
        "vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYU6lNZmQVi4",
        "outputId": "5de6f91c-d45b-4725-f673-0ead11e6dd9c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3666127183.py:3: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
            "  embeddings = HuggingFaceEmbeddings()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8a5ccb3"
      },
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(\n",
        "    temperature=0,\n",
        "    model=\"llama-3.1-8b-instant\"\n",
        ")"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5ef9734"
      },
      "source": [
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
        "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "Use three sentences maximum and keep the answer as concise as possible.\n",
        "{context}\n",
        "Question: {question}\n",
        "Helpful Answer:\"\"\"\n",
        "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm,\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
        ")"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ef6baff",
        "outputId": "e2ec686d-c089-40fe-f1b3-ea53604c2e03"
      },
      "source": [
        "print(\"Enter your query. Type 'exit' to quit.\")\n",
        "while True:\n",
        "    query = input(\"Please enter your query: \")\n",
        "    if query.lower() == 'exit':\n",
        "        break\n",
        "    result = qa_chain({\"query\": query})\n",
        "\n",
        "    print(result[\"result\"])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your query. Type 'exit' to quit.\n",
            "Please enter your query: what is rag\n",
            "RAG (Retrieval-Augmented Generation) is a method that improves large language models (LLMs) by incorporating information retrieval before generating responses. It pulls relevant text from databases, uploaded documents, or web sources to help LLMs stick to the facts and reduce AI hallucinations. RAG was first introduced in a 2020 research paper from Meta.\n",
            "Please enter your query: advantages of rag\n",
            "RAG (Retrieval-Augmented Generation) improves large language models by incorporating information retrieval before generating responses, reducing AI hallucinations and allowing users to verify cited sources. It also saves on computational and financial costs by reducing the need to retrain LLMs with new data. Additionally, RAG provides greater transparency by enabling users to cross-check retrieved content for accuracy and relevance.\n",
            "Please enter your query: limitations of rag\n",
            "RAG (Retrieval-Augmented Generation) has several limitations, including the potential to hallucinate around source material, struggle to recognize knowledge limitations, and generate answers when insufficient information is available. Additionally, RAG models may retrieve factually correct but misleading sources, misinterpret data, and combine outdated and updated information in a misleading manner. RAG also does not eliminate the need for frequent model retraining.\n",
            "Please enter your query: explain what a rag does\n",
            "RAG (Retrieval-Augmented Generation) improves large language models by incorporating information retrieval before generating responses, allowing them to stick to facts and reduce AI hallucinations. It does this by pulling relevant text from databases, uploaded documents, or web sources to augment user queries. This process helps LLMs provide more accurate and transparent responses.\n",
            "Please enter your query: exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VC4WbD4nRFP0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}